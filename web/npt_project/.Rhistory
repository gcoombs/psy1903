if (!all(c("block", "rt", "correct") %in% names(df)) ||
!any(c("trial_type", "trialType") %in% names(df))) {
stop("Input data frame is missing required columns.")
}
## Change correct column to logical
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
rt_min = 250; rt_max = 900
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min &
magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min &
parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
str(df)
is.numeric(df$rt)
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Change correct column to logical
if (!is.logical(df$correct)) {
df$correct <- logical(df$correct)
}
## Change correct column to logical
if (!is.logical(df$correct)) {
df$correct <- logical(df$correct)
}
is.logical(df$correct)
## Change correct column to logical
if (!is.logical(df$correct)) {
df$correct <- as.logical(df$correct)
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min &
magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min &
parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Accuracy 0..1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside [0, 1]. Check 'correct' coding."))
}
}
# Mean RTs within [rt_min, rt_max]
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside [", rt_min, ", ", rt_max, "]."))
}
}
return(participant_summary)
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv"
)
summarize_behavior <- function(df, rt_min = 250, rt_max = 900) {
# Ensure all expected column names are there
if (!all(c("block", "rt", "correct") %in% names(df)) ||
!any(c("trial_type", "trialType") %in% names(df))) {
stop("Input data frame is missing required columns.")
}
## Check if rt column is numeric
if (!is.numeric(df$rt)) {
df$rt <- as.numeric(df$rt)
warning("'rt' column was not numeric. Coerced with as.numeric().")
}
## Change correct column to logical
if (!is.logical(df$correct)) {
df$correct <- as.logical(df$correct)
}
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min &
magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min &
parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Accuracy 0..1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside [0, 1]. Check 'correct' coding."))
}
}
# Mean RTs within [rt_min, rt_max]
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside [", rt_min, ", ", rt_max, "]."))
}
}
return(participant_summary)
}
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
## Clear environment
rm(list = ls())
## Source scripts to load functions
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
## Test the functions on one participant file
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
study_level <- readRDS("~/Desktop/psy1903/web/npt_project/data/cleaned/study_level.rds")
View(study_level)
R.version.string
study_level <- readRDS("~/Desktop/psy1903/web/npt_project/data/cleaned/study_level.rds")
View(study_level)
summary(study_level$tef10_score)
names(study_level)
str(study_level)
names(study_level)
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here("data/cleaned/study_level.csv"))
write.csv(study_level, here::here("data/cleaned/study_level.csv"))
library(here)
if (!require(here)) install.packages("here")
write.csv(study_level, here::here("data/cleaned/study_level.csv"))
study_level <- read.csv(here("data/cleaned/study_level.csv"))
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
study_level <- read.csv(here::here("data/cleaned/study_level.csv"), row.names = FALSE)
study_level$X <- NULL
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
rm(study_level)
study_level <- read.csv(here::here("data/cleaned/study_level.csv"))
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
names(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
names(study_level)
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$magnitude_acc - study_level$parity_acc
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Class-level variability (standard deviations)
sapply(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
sd, na.rm = TRUE)
# Create a focus grouping variable from tef10_score
focus_cut <- mean(study_level$tef10_score, na.rm = TRUE)
study_level$focus_group <- ifelse(study_level$tef10_score >= focus_cut,
"High Focus", "Low Focus")
# Check group counts
table(study_level$focus_group)
# Aggregate reaction times and differences by focus group
rt_by_focus <- aggregate(
study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
rt_by_focus
# Aggregate accuracies and differences by focus group
acc_by_focus <- aggregate(
study_level[, c("magnitude_acc",
"parity_acc",
"acc_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
acc_by_focus
str(study_level)
study_level$focus_group <- as.factor(study_level$focus_group)
str(study_level$focus_group)
For High Focus participants, parity mean RT is approximately `r {
# Summaries for key variables
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
# Optional exploration: association between overall RT and overall accuracy
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
rt_diff
# Summaries for key variables
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
#### Install and Load Packages -------------------------------------------------
if (!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("httr", "jsonlite", "fs", "stringr", "lubridate")
#### Setup ---------------------------------------------------------------------
## 1. Personal Access Token (authentication)
## To allow R to connect to your OSF account:
## Go to OSF → Profile icon (top right) → Settings → Personal Access Tokens.
## Click "Create Token", name it (e.g., "OSF_API"), check all permissions,
## and copy the generated string below. This token works like a password,
## so keep it private and do not share it publicly.
## TOKEN <- "paste_your_token_here"
TOKEN <- "SzqxYX88znq4U5Epy5JV3t8NsH88RWLygXhLq1gi6hj5HWiEfBeQ4ORNaikCObqohPZL8G"
## 2. Project Node ID (location of your data)
## Each OSF project or component has a unique 5-character node ID.
## To find it, open your OSF project in a browser:
## Example URL: https://osf.io/avm5d/
## The part after "osf.io/" (here, "avm5d") is the node ID for that project
## or component. Copy and paste that string below.
## NODE <- "paste_your_node_here"
NODE <- "avm5d"
## Only download files matching this prefix
PREFIX <- "lexical-decision"
## Only download files modified after this date (UTC)
CUTOFF_DATE <- ymd("2025-10-15", tz = "UTC")
#### Fetch file listing --------------------------------------------------------
BASE <- paste0("https://api.osf.io/v2/nodes/", NODE, "/files/osfstorage/")
res <- GET(BASE, add_headers(Authorization = paste("Bearer", TOKEN)))
stop_for_status(res)
page <- fromJSON(content(res, as = "text", encoding = "UTF-8"), flatten = TRUE)
## Follow pagination if present
all <- list(page)
while (!is.null(all[[length(all)]]$links$`next`) && nzchar(all[[length(all)]]$links$`next`)) {
nxt <- all[[length(all)]]$links$`next`
res <- GET(nxt, add_headers(Authorization = paste("Bearer", TOKEN)))
stop_for_status(res)
all[[length(all) + 1]] <- fromJSON(content(res, as = "text", encoding = "UTF-8"), flatten = TRUE)
}
## Combine pages and keep only actual files
rows <- do.call(rbind, lapply(all, function(p) p$data))
files <- subset(rows, attributes.kind == "file")
#### Filter by prefix and modification date ------------------------------------
files$modified <- ymd_hms(files$attributes.date_modified, tz = "UTC")
files_subset <- subset(
files,
str_detect(attributes.name, fixed(PREFIX)) &
modified > CUTOFF_DATE
)
message("Found ", nrow(files_subset), " matching files.")
#### Download ------------------------------------------------------------------
if (!dir_exists("osf_downloads")) dir_create("osf_downloads")
for (i in seq_len(nrow(files_subset))) {
file_id <- files_subset$id[i]
name    <- files_subset$attributes.name[i]
path    <- fs::path("osf_downloads", name)
url <- paste0("https://api.osf.io/v2/files/", file_id, "/?action=download&direct=1")
r <- GET(url, add_headers(Authorization = paste("Bearer", TOKEN)))
stop_for_status(r)
writeBin(content(r, as = "raw"), path)
message("Saved: ", path)
}
#### Remove Intermediate Steps -------------------------------------------------
rm(all, files, files_subset, page, r, res, rows, BASE, CUTOFF_DATE, file_id, i, name, NODE, path, PREFIX, TOKEN, url)
data <- read.csv(here("data", "raw", "npt-experiment-2025-11-05-10-33-05.csv"), stringsAsFactors = FALSE)
data <- read.csv(here::here("data", "raw", "npt-experiment-2025-11-05-10-33-05.csv"), stringsAsFactors = FALSE)
library(here)
data2 <- read.csv(here("data", "raw", "npt-experiment-2025-11-05-10-33-05.csv"), stringsAsFactors = FALSE)
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
file_list
# Prefer a pattern to avoid accidentally pulling other CSVs
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = FALSE)
file_list
file.create("reports/npt_group.qmd")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
View(study_level)
# Quick inspection
print(head(study_level))
str(study_level)
summary(study_level)
names(study_level)
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$parity_mean_rt
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <- study_level$parity_mean_rt - study_level$magnitude_mean_rt
# B) Accuracy difference (complete together)
study_level$acc_diff <- study_level$parity_acc - study_level$magnitude_acc
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Class-level variability (standard deviations)
sapply(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
sd, na.rm = TRUE)
mean(study_level$parity_mean_rt, na.rm = TRUE)
round(mean(study_level$parity_mean_rt, na.rm = TRUE), 2)
# Create a focus grouping variable from tef10_score
focus_cut <- mean(study_level$tef10_score, na.rm = TRUE)
study_level$focus_group <- ifelse(study_level$tef10_score >= focus_cut,
"High Focus", "Low Focus")
# Check group counts
table(study_level$focus_group)
# Aggregate reaction times and differences by focus group
rt_by_focus <- aggregate(
study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
rt_by_focus
rt_by_focus
# Aggregate accuracies and differences by focus group
acc_by_focus <- aggregate(
study_level[, c("magnitude_acc",
"parity_acc",
"acc_diff")],
by = list(Focus = study_level$focus_group),
FUN = mean
)
acc_by_focus
summary(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff",
"magnitude_acc",
"parity_acc",
"acc_diff")])
cor(study_level$mean_rt_overall, study_level$mean_acc_overall, use = "complete.obs")
# Build a compact one-row table of overall means and SDs
group_summary <- data.frame(
mean_magnitude_rt = mean(study_level$magnitude_mean_rt, na.rm = TRUE),
mean_parity_rt    = mean(study_level$parity_mean_rt,    na.rm = TRUE),
mean_rt_diff      = mean(study_level$rt_diff,                    na.rm = TRUE),
sd_magnitude_rt   = sd(study_level$magnitude_mean_rt,   na.rm = TRUE),
sd_parity_rt      = sd(study_level$parity_mean_rt,      na.rm = TRUE),
sd_rt_diff        = sd(study_level$rt_diff,                      na.rm = TRUE)
)
group_summary
write.csv(group_summary, here("output/tables/group_summary.csv"), row.names = FALSE)
saveRDS(group_summary, here("output/tables/group_summary.rds"))
# Make an output directory for tables if needed
dir.create(here("output/tables"), recursive = TRUE, showWarnings = FALSE)
# Build a compact one-row table of overall means and SDs
group_summary <- data.frame(
mean_magnitude_rt = mean(study_level$magnitude_mean_rt, na.rm = TRUE),
mean_parity_rt    = mean(study_level$parity_mean_rt,    na.rm = TRUE),
mean_rt_diff      = mean(study_level$rt_diff,                    na.rm = TRUE),
sd_magnitude_rt   = sd(study_level$magnitude_mean_rt,   na.rm = TRUE),
sd_parity_rt      = sd(study_level$parity_mean_rt,      na.rm = TRUE),
sd_rt_diff        = sd(study_level$rt_diff,                      na.rm = TRUE)
)
write.csv(group_summary, here("output/tables/group_summary.csv"), row.names = FALSE)
saveRDS(group_summary, here("output/tables/group_summary.rds"))
# Confirm
file.exists(here("output/tables/group_summary.csv"))
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
